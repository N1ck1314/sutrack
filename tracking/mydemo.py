#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ D435i åš SUTrack åœ¨çº¿ RGB-Depth è·Ÿè¸ª Demo

è¿è¡Œæ–¹å¼ï¼š
  1) conda activate sutrack
  2) ç¡®ä¿ï¼šexport PYTHONPATH=/ç»å¯¹è·¯å¾„/SUTrack:$PYTHONPATH
  3) python mydemo.py

æ“ä½œè¯´æ˜ï¼š
  - æŒ‰ 's' é”®ï¼šé€‰å–åˆå§‹ç›®æ ‡ï¼ˆç”¨é¼ æ ‡æ¡†é€‰ï¼‰
  - æŒ‰ ESCï¼šé€€å‡º
"""

import time
import cv2
import numpy as np
import pyrealsense2 as rs
import torch
import os
import sys

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥ SUTrack æ¨¡å—
env_path = os.path.join(os.path.dirname(__file__), '..')
if (env_path not in sys.path):
    sys.path.append(env_path)

# ========= 1. RealSense ç›¸æœºéƒ¨åˆ† =========

def create_realsense_pipeline():
    """åˆ›å»ºå¹¶å¯åŠ¨ RealSense pipelineï¼Œå¹¶å¯¹é½æ·±åº¦åˆ°å½©è‰²åæ ‡ç³»ã€‚"""
    pipeline = rs.pipeline()
    config = rs.config()

    # æ ¹æ®è‡ªå·±éœ€è¦è°ƒåˆ†è¾¨ç‡ / FPSï¼ˆå»ºè®®å’Œ GPU å¸¦å®½æƒè¡¡ï¼‰
    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)

    profile = pipeline.start(config)

    # æ·±åº¦å¯¹é½åˆ°å½©è‰²
    align_to = rs.stream.color
    align = rs.align(align_to)

    # æ·±åº¦ scaleï¼ˆå•ä½ï¼šç±³ / depth_unitï¼‰
    depth_sensor = profile.get_device().first_depth_sensor()
    depth_scale = depth_sensor.get_depth_scale()

    print(f"[INFO] RealSense started. depth_scale = {depth_scale:.6f} m/unit")

    return pipeline, align, depth_scale


def grab_rgbd(pipeline, align, timeout_ms=5000, max_retries=3):
    """ä» RealSense è·å–ä¸€å¸§å¯¹é½åçš„ RGB + Depthã€‚"""
    for retry in range(max_retries):
        try:
            frames = pipeline.wait_for_frames(timeout_ms)
            aligned_frames = align.process(frames)

            color_frame = aligned_frames.get_color_frame()
            depth_frame = aligned_frames.get_depth_frame()

            if not color_frame or not depth_frame:
                if retry < max_retries - 1:
                    print(f"[WARNING] Invalid frames, retry {retry + 1}/{max_retries}")
                    continue
                return None, None

            color_image = np.asanyarray(color_frame.get_data())    # (H,W,3) BGR uint8
            depth_image = np.asanyarray(depth_frame.get_data())    # (H,W)   uint16

            return color_image, depth_image
        
        except RuntimeError as e:
            if retry < max_retries - 1:
                print(f"[WARNING] Frame timeout, retry {retry + 1}/{max_retries}: {e}")
                time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
            else:
                print(f"[ERROR] Failed to get frames after {max_retries} retries: {e}")
                raise
    
    return None, None


# ========= 2. é¢„å¤„ç†ï¼šRGB + Depth =========

def preprocess_rgb_depth(color_bgr, depth_raw, depth_scale, max_dist_m=5.0):
    """
    color_bgr: (H,W,3) uint8, BGR
    depth_raw: (H,W)   uint16, raw depth
    depth_scale: D435i æ·±åº¦å•ä½åˆ°ç±³çš„æ¯”ä¾‹ï¼ˆä¸€èˆ¬ ~0.001ï¼‰
    è¿”å›ï¼š
      color_rgb_uint8: (H,W,3) uint8 [0,255]  # RGB 3é€šé“ - ä¾›SUTrackä½¿ç”¨
      depth_3ch_uint8: (H,W,3) uint8 [0,255]  # æ·±åº¦ä¿¡æ¯å¤åˆ¶æˆ3é€šé“ - ä¾›SUTrackä½¿ç”¨
      color_rgb_float: (H,W,3) float32 [0,1]  # RGB floatç‰ˆæœ¬ - ä¾›å¯è§†åŒ–ä½¿ç”¨
      depth_3ch_float: (H,W,3) float32 [0,1]  # æ·±åº¦floatç‰ˆæœ¬ - ä¾›å¯è§†åŒ–ä½¿ç”¨
    
    SUTrack ä¸ºä»€ä¹ˆéœ€è¦6é€šé“ï¼Ÿ
    - é€šé“ 0-2: RGB å½©è‰²ä¿¡æ¯ (çº¢ã€ç»¿ã€è“)
    - é€šé“ 3-5: æ·±åº¦ä¿¡æ¯ (å¤åˆ¶3æ¬¡ï¼Œä¿æŒä¸RGBç›¸åŒçš„ç»´åº¦ç»“æ„)
    
    âš ï¸ é‡è¦ï¼šSUTrackçš„PreprocessoræœŸæœ›uint8 [0-255]è¾“å…¥ï¼Œå†…éƒ¨ä¼šé™¤ä»¥255å½’ä¸€åŒ–
    """
    # 1) BGR -> RGB, uint8 [0,255] for SUTrack
    color_rgb_uint8 = cv2.cvtColor(color_bgr, cv2.COLOR_BGR2RGB)

    # 2) raw depth -> meters -> uint8 [0,255]
    depth_m = depth_raw.astype(np.float32) * float(depth_scale)
    depth_m = np.clip(depth_m, 0.0, max_dist_m)
    depth_norm = depth_m / max_dist_m  # [0,1]
    depth_uint8 = (depth_norm * 255.0).astype(np.uint8)

    # 3) æ‰©å±•æˆ3é€šé“ uint8ç‰ˆæœ¬ for SUTrack
    depth_3ch_uint8 = np.stack([depth_uint8, depth_uint8, depth_uint8], axis=2)
    
    # 4) åŒæ—¶å‡†å¤‡floatç‰ˆæœ¬ä¾›å¯è§†åŒ–ä½¿ç”¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
    color_rgb_float = color_rgb_uint8.astype(np.float32) / 255.0
    depth_3ch_float = np.stack([depth_norm, depth_norm, depth_norm], axis=2)

    return color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float


# ========= 3. SUTrack æ¥å£å°è£…ï¼ˆä½¿ç”¨æ ‡å‡† Tracker ç±»ï¼‰ =========

class SUTrackOnlineTracker:
    """
    åœ¨çº¿è·Ÿè¸ªå°è£…ï¼š
      - ä½¿ç”¨æ ‡å‡†çš„ lib.test.evaluation.tracker.Tracker ç±»
      - ä¸ test.py ä¸­çš„å®ç°æ–¹å¼å®Œå…¨ä¸€è‡´
    """

    def __init__(self, tracker_name="sutrack", tracker_param="sutrack_b224", dataset_name='demo', 
                 checkpoint_path=None):
        """
        ä½¿ç”¨æ ‡å‡† Tracker ç±»åˆ›å»ºè·Ÿè¸ªå™¨
        
        Args:
            tracker_name: è·Ÿè¸ªå™¨åç§°
            tracker_param: å‚æ•°é…ç½®å
            dataset_name: æ•°æ®é›†åç§°
            checkpoint_path: æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
        """
        print(f"[INFO] Creating tracker: {tracker_name} with param: {tracker_param}")
        if checkpoint_path:
            print(f"[INFO] Using checkpoint: {checkpoint_path}")
        
        try:
            # å¯¼å…¥æ ‡å‡†çš„ Tracker ç±»ï¼ˆä¸ test.py ç›¸åŒï¼‰
            from lib.test.evaluation.tracker import Tracker
            
            # åˆ›å»º Tracker å®ä¾‹ï¼ˆè¿™åªæ˜¯ä¸ªåŒ…è£…å™¨ï¼‰
            tracker_wrapper = Tracker(tracker_name, tracker_param, dataset_name, run_id=None)
            
            # è·å–å‚æ•°
            params = tracker_wrapper.get_parameters()
            
            # å¦‚æœæŒ‡å®šäº† checkpoint è·¯å¾„ï¼Œè¦†ç›–é»˜è®¤é…ç½®
            if checkpoint_path:
                params.checkpoint = checkpoint_path
                print(f"[INFO] Overriding checkpoint path to: {checkpoint_path}")
            
            # æ·»åŠ ç¼ºå¤±çš„å‚æ•°ï¼ˆé¿å… AttributeErrorï¼‰
            if not hasattr(params, 'debug'):
                params.debug = 0  # 0 = ä¸è°ƒè¯•, 1 = æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
            # ğŸ”§ ç¦ç”¨æ–‡æœ¬æ¨¡æ€å’ŒCLIP
            print(f"[INFO] Disabling text modality and CLIP...")
            self._disable_text_modality(params)
            
            # ğŸ” æ£€æŸ¥æ¨¡å‹è¾“å…¥é€šé“æ•°
            print(f"[INFO] Checking model input configuration...")
            self._check_model_channels(params)
            
            # ğŸ¯ ä¼˜åŒ–ï¼šå¯ç”¨æ¨¡æ¿æ›´æ–°ä»¥æé«˜è·Ÿè¸ªç²¾åº¦
            print("[INFO] Applying tracking optimizations...")
            # è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°ï¼Œå¯ç”¨æ¨¡æ¿æ›´æ–°
            params.cfg.TEST.UPDATE_INTERVALS.DEFAULT = 25       # æ¯25å¸§æ›´æ–°ä¸€æ¬¡æ¨¡æ¿
            params.cfg.TEST.UPDATE_THRESHOLD.DEFAULT = 0.85     # ğŸ”’ æé«˜é˜ˆå€¼åˆ°0.85ï¼Œåªåœ¨éå¸¸ç¡®ä¿¡æ—¶æ›´æ–°
            params.cfg.TEST.NUM_TEMPLATES = 2                   # ä½¿ç”¨2ä¸ªæ¨¡æ¿ï¼ˆå½“å‰å¸§+å†å²å¸§ï¼‰
            print(f"[INFO] Template update enabled: interval=25, threshold=0.85 (strict), num_templates=2")
            print(f"[INFO] âš ï¸  Conservative update: Only update when confidence > 0.85 to prevent drift")
            
            # å¯ç”¨è°ƒè¯•æ¨¡å¼ä»¥æ˜¾ç¤ºæ¨¡æ¿æ›´æ–°ä¿¡æ¯
            params.debug = 0  # ä¿æŒä¸º0ï¼Œæˆ‘ä»¬ä¼šåœ¨wrapperä¸­æ·»åŠ è°ƒè¯•
            
            # åˆ›å»ºçœŸæ­£çš„è·Ÿè¸ªå™¨å®ä¾‹ï¼ˆä¸ run_sequence ä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
            self.tracker = tracker_wrapper.create_tracker(params)
            
            self.initialized = False
            self.last_bbox = None
            self.last_confidence = 0.0  # ç”¨äºæ˜¾ç¤ºè·Ÿè¸ªç½®ä¿¡åº¦
            
            print("[INFO] Tracker created successfully using standard Tracker class.")
            
        except Exception as e:
            print(f"[ERROR] åˆ›å»º Tracker å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _disable_text_modality(self, params):
        """ç¦ç”¨æ–‡æœ¬æ¨¡æ€å’ŒCLIPç›¸å…³åŠŸèƒ½"""
        cfg = params.cfg
        
        print("[INFO] ğŸ”§ Configuring vision-only mode...")
        
        # ç¦ç”¨æ–‡æœ¬ç¼–ç å™¨
        if hasattr(cfg.MODEL, 'TEXT_ENCODER'):
            print("[INFO]    - Disabling text encoder...")
            cfg.MODEL.TEXT_ENCODER = None  # å®Œå…¨ç¦ç”¨æ–‡æœ¬ç¼–ç å™¨
        
        # ç¦ç”¨å¤šæ¨¡æ€è¯­è¨€åŠŸèƒ½
        if hasattr(cfg.DATA, 'MULTI_MODAL_LANGUAGE'):
            print("[INFO]    - Disabling multi-modal language in DATA...")
            cfg.DATA.MULTI_MODAL_LANGUAGE = False
        
        # ç¦ç”¨æ‰€æœ‰æ•°æ®é›†çš„NLPåŠŸèƒ½
        if hasattr(cfg.DATA, 'USE_NLP'):
            print("[INFO]    - Disabling NLP for all datasets...")
            for dataset_key in cfg.DATA.USE_NLP:
                cfg.DATA.USE_NLP[dataset_key] = False
        
        # è®­ç»ƒæ—¶ä¹Ÿç¦ç”¨è¯­è¨€æ¨¡æ€ï¼ˆå³ä½¿è¿™æ˜¯æ¨ç†ï¼‰
        if hasattr(cfg.TRAIN, 'TYPE') and 'text' in cfg.TRAIN.TYPE:
            print("[INFO]    - Adjusting training type to vision-only...")
            cfg.TRAIN.TYPE = 'vision_only'
        
        # æµ‹è¯•æ—¶ç¦ç”¨è¯­è¨€æ¨¡æ€
        if hasattr(cfg.TEST, 'MULTI_MODAL_LANGUAGE'):
            print("[INFO]    - Disabling language modality in TEST...")
            if isinstance(cfg.TEST.MULTI_MODAL_LANGUAGE, dict):
                for key in cfg.TEST.MULTI_MODAL_LANGUAGE:
                    cfg.TEST.MULTI_MODAL_LANGUAGE[key] = False
            else:
                cfg.TEST.MULTI_MODAL_LANGUAGE = False
        
        # æµ‹è¯•æ—¶ç¦ç”¨NLP
        if hasattr(cfg.TEST, 'USE_NLP'):
            print("[INFO]    - Disabling NLP in TEST...")
            if isinstance(cfg.TEST.USE_NLP, dict):
                for key in cfg.TEST.USE_NLP:
                    cfg.TEST.USE_NLP[key] = False
            else:
                cfg.TEST.USE_NLP = False
        
        # ç¡®ä¿åªä½¿ç”¨è§†è§‰æ¨¡æ€
        if hasattr(cfg.TEST, 'MULTI_MODAL_VISION'):
            print("[INFO]    - Ensuring vision modality is enabled...")
            if isinstance(cfg.TEST.MULTI_MODAL_VISION, dict):
                for key in cfg.TEST.MULTI_MODAL_VISION:
                    cfg.TEST.MULTI_MODAL_VISION[key] = True
            else:
                cfg.TEST.MULTI_MODAL_VISION = True
        
        # å¦‚æœæœ‰æ•°æ®é¢„å¤„ç†ç›¸å…³çš„è®¾ç½®
        if hasattr(cfg.DATA, 'MULTI_MODAL_VISION'):
            print("[INFO]    - Enabling vision processing...")
            cfg.DATA.MULTI_MODAL_VISION = True
        
        # ğŸ”§ å¼ºåˆ¶å¯ç”¨RGBDæ”¯æŒ
        print("[INFO]    - Configuring RGBD support...")
        self._force_rgbd_support(cfg)
        
        print("[SUCCESS] âœ… Vision-only mode configured - Text/CLIP bypassed")
    
    def _force_rgbd_support(self, cfg):
        """å¼ºåˆ¶é…ç½®RGBDæ”¯æŒ"""
        
        # 1. è®¾ç½®ç¼–ç å™¨è¾“å…¥é€šé“ä¸º6
        if hasattr(cfg.MODEL, 'ENCODER'):
            print("[INFO]       - Setting encoder input channels to 6...")
            cfg.MODEL.ENCODER.IN_CHANS = 6  # å¼ºåˆ¶è®¾ç½®ä¸º6é€šé“
            if hasattr(cfg.MODEL.ENCODER, 'in_chans'):
                cfg.MODEL.ENCODER.in_chans = 6
        
        # 2. æ‰©å±•æ•°æ®å½’ä¸€åŒ–å‚æ•°åˆ°6é€šé“
        if hasattr(cfg.DATA, 'MEAN') and len(cfg.DATA.MEAN) == 3:
            print("[INFO]       - Extending normalization parameters to 6 channels...")
            # RGBé€šé“çš„å½’ä¸€åŒ–å‚æ•°
            rgb_mean = list(cfg.DATA.MEAN)  # [0.485, 0.456, 0.406]
            rgb_std = list(cfg.DATA.STD)    # [0.229, 0.224, 0.225]
            
            # ä¸ºæ·±åº¦é€šé“æ·»åŠ å½’ä¸€åŒ–å‚æ•°ï¼ˆä½¿ç”¨é€‚åˆæ·±åº¦çš„å‚æ•°ï¼‰
            # æ·±åº¦é€šé“ä½¿ç”¨ä¸åŒçš„å½’ä¸€åŒ–å‚æ•°ï¼Œå› ä¸ºæ·±åº¦å€¼åˆ†å¸ƒä¸RGBä¸åŒ
            depth_mean = [0.5, 0.5, 0.5]   # æ·±åº¦å½’ä¸€åŒ–åˆ°[0,1]ï¼Œæ‰€ä»¥å‡å€¼ç”¨0.5
            depth_std = [0.5, 0.5, 0.5]    # æ·±åº¦æ ‡å‡†å·®ç”¨0.5
            
            # æ‰©å±•åˆ°6é€šé“ï¼šRGB + Depth
            cfg.DATA.MEAN = rgb_mean + depth_mean
            cfg.DATA.STD = rgb_std + depth_std
            
            print(f"[INFO]       - New MEAN (RGB+Depth): {cfg.DATA.MEAN}")
            print(f"[INFO]       - New STD (RGB+Depth): {cfg.DATA.STD}")
        
        # 3. ç¡®ä¿å¤šæ¨¡æ€è§†è§‰å¼€å¯
        if hasattr(cfg.DATA, 'MULTI_MODAL_VISION'):
            cfg.DATA.MULTI_MODAL_VISION = True
        
        print("[INFO]       - RGBD support configured successfully")

    def _check_model_channels(self, params):
        """æ£€æŸ¥æ¨¡å‹è¾“å…¥é€šé“é…ç½®"""
        cfg = params.cfg
        
        print("\n" + "="*60)
        print("[ğŸ” MODEL CHANNEL ANALYSIS]")
        print("="*60)
        
        # æ£€æŸ¥ç¼–ç å™¨è¾“å…¥é€šé“æ•°
        if hasattr(cfg.MODEL, 'ENCODER'):
            encoder_cfg = cfg.MODEL.ENCODER
            print(f"[INFO] Encoder type: {getattr(encoder_cfg, 'TYPE', 'Unknown')}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥é€šé“é…ç½®
            input_channels = None
            for attr in ['IN_CHANS', 'INPUT_CHANNELS', 'in_chans']:
                if hasattr(encoder_cfg, attr):
                    input_channels = getattr(encoder_cfg, attr)
                    print(f"[INFO] Found input channels config: {attr} = {input_channels}")
                    break
            
            if input_channels is None:
                print("[WARNING] No explicit input channel configuration found")
                print("[INFO] Will check default model behavior...")
            elif input_channels == 6:
                print("[SUCCESS] âœ… Model configured for RGBD input (6 channels)")
                print("[INFO]    - Channels 0-2: RGB")
                print("[INFO]    - Channels 3-5: Depth (replicated)")
            elif input_channels == 3:
                print("[WARNING] âš ï¸  Model configured for RGB-only input (3 channels)")
                print("[INFO] This may not utilize depth information properly")
            else:
                print(f"[WARNING] âš ï¸  Unexpected channel count: {input_channels}")
        
        # æ£€æŸ¥æ•°æ®é…ç½®
        if hasattr(cfg, 'DATA'):
            data_cfg = cfg.DATA
            multi_modal = getattr(data_cfg, 'MULTI_MODAL_VISION', 'Unknown')
            print(f"[INFO] Multi-modal vision enabled: {multi_modal}")
            
            # æ£€æŸ¥æ•°æ®é¢„å¤„ç†é…ç½®
            if hasattr(data_cfg, 'MEAN') and hasattr(data_cfg, 'STD'):
                mean = data_cfg.MEAN
                std = data_cfg.STD
                print(f"[INFO] Data normalization - MEAN: {mean}")
                print(f"[INFO] Data normalization - STD: {std}")
                
                if len(mean) == 6 and len(std) == 6:
                    print("[SUCCESS] âœ… Normalization configured for 6 channels (RGBD)")
                elif len(mean) == 3 and len(std) == 3:
                    print("[INFO] Normalization configured for 3 channels (RGB)")
                    print("[WARNING] âš ï¸  This suggests RGB-only processing")
        
        print("="*60 + "\n")

    def initialize(self, color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float, init_bbox):
        """
        åˆå§‹åŒ–è·Ÿè¸ªå™¨ã€‚

        color_rgb_uint8: (H,W,3) uint8 [0,255]  # RGB 3é€šé“ - ä¾›SUTrackä½¿ç”¨
        depth_3ch_uint8: (H,W,3) uint8 [0,255]  # æ·±åº¦ 3é€šé“ - ä¾›SUTrackä½¿ç”¨
        color_rgb_float: (H,W,3) float32 [0,1]  # RGB floatç‰ˆæœ¬ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        depth_3ch_float: (H,W,3) float32 [0,1]  # æ·±åº¦floatç‰ˆæœ¬ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        init_bbox: [x, y, w, h]ï¼Œå›¾åƒåæ ‡
        
        æœ€ç»ˆè¾“å…¥ç»™SUTrackçš„æ˜¯6é€šé“uint8å›¾åƒï¼š
        - å‰3é€šé“ï¼šRGBå½©è‰²ä¿¡æ¯ [0-255]
        - å3é€šé“ï¼šæ·±åº¦ä¿¡æ¯ï¼ˆé‡å¤3æ¬¡ï¼‰[0-255]
        """
        print("\n" + "="*60)
        print("[INFO] Starting tracker initialization...")
        print("="*60)
        
        try:
            # åˆå¹¶ RGB(3é€šé“) å’Œ Depth(3é€šé“) = æ€»å…±6é€šé“ uint8
            rgbd_image = np.concatenate([color_rgb_uint8, depth_3ch_uint8], axis=2)  # (H,W,6) uint8
            
            # ğŸ” è¯¦ç»†åˆ†æè¾“å…¥æ•°æ®
            self._analyze_input_data(color_rgb_uint8, depth_3ch_uint8, rgbd_image)
            
            print(f"[DEBUG] RGBD image shape: {rgbd_image.shape}, dtype: {rgbd_image.dtype}")
            print(f"[DEBUG] Value range: [{rgbd_image.min()}, {rgbd_image.max()}]")
            print(f"[DEBUG] Init bbox: {init_bbox}")
            
            # å‡†å¤‡åˆå§‹åŒ–ä¿¡æ¯
            init_info = {
                'init_bbox': init_bbox,  # [x, y, w, h]
            }
            
            print(f"[DEBUG] Calling tracker.initialize()...")
            
            # è°ƒç”¨è·Ÿè¸ªå™¨åˆå§‹åŒ–ï¼ˆä½¿ç”¨ tracker_implï¼‰
            out = self.tracker.initialize(rgbd_image, init_info)
            
            print(f"[DEBUG] Tracker.initialize() returned: {type(out)}")
            
            self.initialized = True
            self.last_bbox = init_bbox
            
            print("\n" + "="*60)
            print(f"[SUCCESS] âœ“ Tracker initialized successfully!")
            print(f"[SUCCESS] âœ“ Init bbox: {init_bbox}")
            print("="*60 + "\n")
            
        except Exception as e:
            print("\n" + "="*60)
            print(f"[ERROR] âœ— Tracker initialization FAILED!")
            print(f"[ERROR] âœ— Error: {e}")
            print("="*60)
            import traceback
            traceback.print_exc()
            print("="*60 + "\n")
            self.initialized = False

    def _analyze_input_data(self, color_rgb, depth_3ch, rgbd_combined):
        """åˆ†æè¾“å…¥æ•°æ®ç‰¹å¾"""
        print("\n" + "="*60)
        print("[ğŸ” INPUT DATA ANALYSIS]")
        print("="*60)
        
        # RGBåˆ†æ
        print(f"[RGB] Shape: {color_rgb.shape}, dtype: {color_rgb.dtype}")
        print(f"[RGB] Value range: [{color_rgb.min():.1f}, {color_rgb.max():.1f}]")
        rgb_mean = color_rgb.mean(axis=(0,1))
        print(f"[RGB] Channel means: R={rgb_mean[0]:.1f}, G={rgb_mean[1]:.1f}, B={rgb_mean[2]:.1f}")
        
        # æ·±åº¦åˆ†æ
        print(f"[DEPTH] Shape: {depth_3ch.shape}, dtype: {depth_3ch.dtype}")
        print(f"[DEPTH] Value range: [{depth_3ch.min():.1f}, {depth_3ch.max():.1f}]")
        depth_mean = depth_3ch.mean(axis=(0,1))
        print(f"[DEPTH] Channel means: D1={depth_mean[0]:.1f}, D2={depth_mean[1]:.1f}, D3={depth_mean[2]:.1f}")
        
        # æ£€æŸ¥æ·±åº¦æ˜¯å¦æœ‰æ•ˆï¼ˆéå…¨é›¶ï¼‰
        depth_nonzero_ratio = np.count_nonzero(depth_3ch) / depth_3ch.size
        print(f"[DEPTH] Non-zero ratio: {depth_nonzero_ratio:.3f}")
        
        if depth_nonzero_ratio < 0.1:
            print("[WARNING] âš ï¸  Very low depth data! Possible issues:")
            print("          - Depth sensor not working properly")
            print("          - Target too far (>5m)")
            print("          - Depth alignment issues")
        elif depth_nonzero_ratio > 0.5:
            print("[SUCCESS] âœ… Good depth coverage")
        else:
            print("[INFO] Moderate depth coverage")
        
        # RGBDç»„åˆåˆ†æ
        print(f"[RGBD] Combined shape: {rgbd_combined.shape}")
        print(f"[RGBD] Total channels: {rgbd_combined.shape[2]}")
        
        if rgbd_combined.shape[2] == 6:
            print("[SUCCESS] âœ… 6-channel RGBD input prepared correctly")
            print("[INFO]    - Channels 0-2: RGB color information")
            print("[INFO]    - Channels 3-5: Depth information (replicated)")
            
            # æ£€æŸ¥RGBå’Œæ·±åº¦çš„åŒºåˆ«
            rgb_part = rgbd_combined[:,:,:3]
            depth_part = rgbd_combined[:,:,3:]
            
            # è®¡ç®—RGBå’Œæ·±åº¦éƒ¨åˆ†çš„å·®å¼‚
            if not np.array_equal(rgb_part, depth_part):
                print("[SUCCESS] âœ… RGB and depth channels contain different information")
            else:
                print("[ERROR] âŒ RGB and depth channels are identical! Check preprocessing.")
        else:
            print(f"[ERROR] âŒ Unexpected channel count: {rgbd_combined.shape[2]}")
        
        print("="*60 + "\n")

    def track(self, color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float, frame_id):
        """
        è¿›è¡Œå•å¸§è·Ÿè¸ªï¼Œè¿”å› bbox = [x, y, w, h]ã€‚
        
        åŒæ ·å°†RGB(3é€šé“) + Depth(3é€šé“) = 6é€šé“uint8è¾“å…¥ç»™ç½‘ç»œ
        """
        if not self.initialized:
            print("[WARNING] Tracker not initialized. Returning default bbox.")
            return [0, 0, 50, 50]

        try:
            # åˆå¹¶ä¸º6é€šé“uint8è¾“å…¥
            rgbd_image = np.concatenate([color_rgb_uint8, depth_3ch_uint8], axis=2)  # (H,W,6) uint8
            
            # ğŸ” å®šæœŸæ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡
            if frame_id % 100 == 0:  # æ¯100å¸§æ£€æŸ¥ä¸€æ¬¡
                self._monitor_input_quality(rgbd_image, frame_id)
            
            # è°ƒç”¨è·Ÿè¸ªæ–¹æ³•ï¼ˆä½¿ç”¨ tracker_implï¼‰
            out = self.tracker.track(rgbd_image)
            
            # æ‰“å°è¾“å‡ºç»“æ„ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
            if not hasattr(self, '_track_debug_done'):
                print(f"[DEBUG] Track output type: {type(out)}")
                if isinstance(out, dict):
                    print(f"[DEBUG] Track output keys: {list(out.keys())}")
                self._track_debug_done = True
            
            # ä»è¾“å‡ºä¸­æå– bbox å’Œç½®ä¿¡åº¦
            bbox, confidence = self._extract_bbox_from_output(out)
            
            # ä¿å­˜ç½®ä¿¡åº¦ä¾›æ˜¾ç¤ºä½¿ç”¨
            self.last_confidence = confidence
            
            # ğŸ”’ å®‰å…¨æ£€æŸ¥ï¼šæ£€æµ‹è·Ÿè¸ªæ¼‚ç§»å¹¶é˜»æ­¢é”™è¯¯æ¨¡æ¿æ›´æ–°
            if not hasattr(self, '_confidence_history'):
                self._confidence_history = []
            self._confidence_history.append(confidence)
            if len(self._confidence_history) > 10:
                self._confidence_history.pop(0)
            
            # è®¡ç®—è¿‘10å¸§çš„å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = sum(self._confidence_history) / len(self._confidence_history)
            
            # ğŸš¨ æ¼‚ç§»æ£€æµ‹ï¼šå¦‚æœç½®ä¿¡åº¦æŒç»­ä¸‹é™æˆ–æ³¢åŠ¨å¤§ï¼Œå¯èƒ½å·²ç»æ¼‚ç§»
            is_drifting = False
            if len(self._confidence_history) >= 5:
                recent_5 = self._confidence_history[-5:]
                # æ£€æµ‹1: æœ€è¿‘5å¸§å¹³å‡ç½®ä¿¡åº¦ < 0.6
                if sum(recent_5) / 5 < 0.6:
                    is_drifting = True
                # æ£€æµ‹2: ç½®ä¿¡åº¦æ³¢åŠ¨è¿‡å¤§ï¼ˆæ ‡å‡†å·® > 0.2ï¼‰
                mean_conf = sum(recent_5) / 5
                variance = sum((x - mean_conf) ** 2 for x in recent_5) / 5
                std_dev = variance ** 0.5
                if std_dev > 0.2:
                    is_drifting = True
            
            # ğŸ” æ£€æµ‹æ¨¡æ¿æ˜¯å¦æ›´æ–°ï¼ˆé€šè¿‡æ¯”è¾ƒæ¨¡æ¿åˆ—è¡¨é•¿åº¦å˜åŒ–ï¼‰
            if hasattr(self.tracker, 'template_list'):
                current_template_count = len(self.tracker.template_list)
                if not hasattr(self, '_last_template_count'):
                    self._last_template_count = current_template_count
                elif current_template_count != self._last_template_count:
                    status = "âœ… SAFE" if not is_drifting else "âš ï¸  RISKY"
                    print(f"\n[ğŸ”„ TEMPLATE UPDATE] Frame {self.tracker.frame_id}: "
                          f"Conf={confidence:.3f}, AvgConf={avg_confidence:.3f}, Status={status}")
                    if is_drifting:
                        print(f"   âš ï¸  Warning: Possible drift detected! Consider re-initialization.")
                    self._last_template_count = current_template_count
            
            # ğŸ” å®šæœŸæ‰“å°è·Ÿè¸ªçŠ¶æ€
            if hasattr(self.tracker, 'frame_id'):
                frame = self.tracker.frame_id
                if frame % 25 == 0:  # æ¯25å¸§æ‰“å°ä¸€æ¬¡ï¼ˆå¯¹åº”æ›´æ–°é—´éš”ï¼‰
                    update_interval = self.tracker.update_intervals
                    update_threshold = self.tracker.update_threshold
                    will_check = "Will check" if frame % update_interval == 0 else "No check"
                    passed_threshold = "âœ“" if confidence > update_threshold else "âœ—"
                    drift_status = "âš ï¸ DRIFTING" if is_drifting else "âœ… Stable"
                    print(f"[ğŸ“Š Status] Frame {frame}: Conf={confidence:.3f} {passed_threshold}, "
                          f"AvgConf={avg_confidence:.3f}, {drift_status}, "
                          f"Update: {will_check} (threshold={update_threshold:.2f})")
            
            if bbox is not None and len(bbox) == 4:
                # éªŒè¯ bbox æ˜¯å¦åˆç†
                if all(isinstance(v, (int, float)) for v in bbox) and bbox[2] > 0 and bbox[3] > 0:
                    self.last_bbox = bbox
                else:
                    print(f"[WARNING] Invalid bbox values: {bbox}, using last bbox")
                    bbox = self.last_bbox if self.last_bbox is not None else [0, 0, 50, 50]
            else:
                print(f"[WARNING] Invalid bbox format: {bbox}, using last bbox")
                bbox = self.last_bbox if self.last_bbox is not None else [0, 0, 50, 50]
            
            return bbox
            
        except Exception as e:
            print(f"[WARNING] Tracking failed: {e}")
            import traceback
            traceback.print_exc()
            # å…œåº•æ–¹æ¡ˆï¼šè¿”å›ä¸Šä¸€å¸§çš„ bbox
            return self.last_bbox if self.last_bbox is not None else [0, 0, 50, 50]

    def _monitor_input_quality(self, rgbd_image, frame_id):
        """ç›‘æ§è¾“å…¥æ•°æ®è´¨é‡"""
        rgb_part = rgbd_image[:,:,:3]
        depth_part = rgbd_image[:,:,3:]
        
        # æ£€æŸ¥æ·±åº¦æ•°æ®è´¨é‡
        depth_nonzero = np.count_nonzero(depth_part) / depth_part.size
        rgb_var = np.var(rgb_part)
        depth_var = np.var(depth_part)
        
        print(f"\n[ğŸ“Š QUALITY CHECK - Frame {frame_id}]")
        print(f"   Depth coverage: {depth_nonzero:.3f}")
        print(f"   RGB variance: {rgb_var:.1f}")
        print(f"   Depth variance: {depth_var:.1f}")
        
        if depth_nonzero < 0.2:
            print("   âš ï¸  Warning: Low depth coverage")
        if depth_var < 100:
            print("   âš ï¸  Warning: Low depth variation")

    def _extract_bbox_from_output(self, output):
        """ä»è·Ÿè¸ªå™¨è¾“å‡ºä¸­æå–bboxå’Œç½®ä¿¡åº¦"""
        bbox = None
        confidence = 0.0
        
        if isinstance(output, dict):
            # æå– bbox
            for key in ['target_bbox', 'bbox', 'pred_bbox', 'box']:
                if key in output:
                    bbox = output[key]
                    break
            else:
                print(f"[DEBUG] Output dict keys: {list(output.keys())}")
                return self.last_bbox, 0.0
            
            # æå–ç½®ä¿¡åº¦
            for key in ['best_score', 'confidence', 'score', 'conf']:
                if key in output:
                    confidence = output[key]
                    if isinstance(confidence, torch.Tensor):
                        confidence = confidence.item()
                    break
                    
        elif hasattr(output, 'target_bbox'):
            bbox = output.target_bbox
            confidence = getattr(output, 'best_score', 0.0)
        elif hasattr(output, 'bbox'):
            bbox = output.bbox
            confidence = getattr(output, 'score', 0.0)
        elif isinstance(output, (list, tuple, np.ndarray)) and len(output) == 4:
            bbox = output
        else:
            print(f"[DEBUG] Unexpected output type: {type(output)}")
            return self.last_bbox, 0.0
        
        # ç¡®ä¿bboxæ˜¯æ­£ç¡®çš„æ ¼å¼
        if isinstance(bbox, torch.Tensor):
            bbox = bbox.detach().cpu().numpy()
        if isinstance(bbox, np.ndarray):
            bbox = bbox.tolist()
        elif not isinstance(bbox, list):
            bbox = list(bbox) if bbox is not None else self.last_bbox
        
        return bbox, confidence


# å¤‡é€‰å®ç°ï¼šå¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
class SimpleSUTracker:
    """ç®€åŒ–ç‰ˆè·Ÿè¸ªå™¨å®ç°"""
    
    def __init__(self):
        print("[INFO] Using simplified tracker (fallback)")
        self.initialized = False
        self.last_bbox = None
        
    def initialize(self, color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float, init_bbox):
        self.last_bbox = init_bbox
        self.initialized = True
        print(f"[INFO] Simple tracker initialized with bbox={init_bbox}")
        
    def track(self, color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float, frame_id):
        if not self.initialized:
            return [0, 0, 50, 50]
        
        # ç®€å•çš„è·Ÿè¸ªï¼šä¿æŒå›ºå®šä½ç½®ï¼ˆä»…ä½œä¸ºå…œåº•ï¼‰
        return self.last_bbox if self.last_bbox is not None else [0, 0, 50, 50]


# ========= 4. ä¸»å¾ªç¯ï¼šä» D435i æ‹‰æµ + SUTrack åœ¨çº¿è·Ÿè¸ª =========
def main():
    print("[INFO] Initializing RealSense camera...")
    pipeline, align, depth_scale = create_realsense_pipeline()
    
    print("[INFO] Waiting for camera to stabilize...")
    # ç­‰å¾…ç›¸æœºç¨³å®šï¼Œä¸¢å¼ƒå‰å‡ å¸§
    for _ in range(30):
        try:
            frames = pipeline.wait_for_frames(timeout_ms=1000)
        except:
            pass
    
    print("[INFO] Initializing SUTrack tracker...")
    
    # ğŸ”§ ä¿®å¤ï¼šå°è¯•å¤šä¸ªé…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨æœ‰checkpointçš„
    tracker = None
    
    # å°è¯•çš„é…ç½®åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    config_attempts = [
        ("sutrack", "sutrack_b224", "/home/nick/code/code.sutrack/SUTrack/checkpoints_backup/train/sutrack/sutrack_b224/SUTRACK_ep0180.pth.tar"),
        ("sutrack", "sutrack_t224", "/home/nick/code/code.sutrack/SUTrack/checkpoints_backup/train/sutrack/sutrack_t224/SUTRACK_ep0180.pth.tar"), 
        ("sutrack", "sutrack_b224", None),  # ä¸æŒ‡å®šcheckpointè·¯å¾„
        ("sutrack", "sutrack_t224", None),  # ä¸æŒ‡å®šcheckpointè·¯å¾„
    ]
    
    for tracker_name, tracker_param, checkpoint_path in config_attempts:
        if checkpoint_path and not os.path.exists(checkpoint_path):
            print(f"[INFO] Checkpoint not found: {os.path.basename(checkpoint_path)}, skipping...")
            continue
            
        try:
            print(f"\n[INFO] Attempting to create tracker: {tracker_name} + {tracker_param}")
            if checkpoint_path:
                print(f"[INFO] Using checkpoint: {os.path.basename(checkpoint_path)}")
            else:
                print(f"[INFO] Using default checkpoint path")
            
            tracker = SUTrackOnlineTracker(
                tracker_name=tracker_name,
                tracker_param=tracker_param,
                dataset_name='demo',
                checkpoint_path=checkpoint_path
            )
            
            print(f"[SUCCESS] âœ… Tracker created successfully with {tracker_param}!")
            break
            
        except FileNotFoundError as e:
            if "pretrained" in str(e):
                print(f"[WARNING] âš ï¸  Missing pretrained encoder file: {e}")
                print(f"[INFO] ğŸ”§ This config requires pretrained encoder, trying next config...")
            else:
                print(f"[WARNING] âš ï¸  File not found: {e}")
            continue
        except Exception as e:
            print(f"[WARNING] âš ï¸  Failed with {tracker_param}: {e}")
            continue
    
    # å¦‚æœæ‰€æœ‰æ ‡å‡†æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
    if tracker is None:
        print("\n" + "="*60)
        print("[WARNING] âš ï¸  All standard tracker creation methods failed!")
        print("[INFO] ğŸ”§ Falling back to simplified tracker...")
        print("="*60)
        tracker = SimpleSUTracker()
    
    frame_id = 0
    init_bbox = None

    win_name = "SUTrack RGB-D Online Tracking (D435i)"
    cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)

    print("[INFO] Starting tracking loop...")
    try:
        while True:
            try:
                color_bgr, depth_raw = grab_rgbd(pipeline, align, timeout_ms=2000, max_retries=2)
            except RuntimeError as e:
                print(f"[ERROR] Camera error: {e}")
                print("[INFO] Trying to reinitialize camera...")
                pipeline.stop()
                time.sleep(1)
                pipeline, align, depth_scale = create_realsense_pipeline()
                continue
            
            if color_bgr is None:
                print("[WARNING] Failed to get frame, skipping...")
                continue

            vis = color_bgr.copy()

            # ç¬¬ä¸€æ¬¡ï¼šç­‰å¾…ç”¨æˆ·æŒ‰ 's' é€‰æ¡†
            if init_bbox is None:
                cv2.putText(vis, "Press 's' to select ROI, ESC to quit",
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                            (0, 0, 255), 2)
                cv2.imshow(win_name, vis)
                key = cv2.waitKey(1) & 0xFF

                if key == 27:  # ESC
                    break

                if key == ord('s'):
                    # æš‚åœå½“å‰ç”»é¢ï¼Œè®©ä½ ç”¨é¼ æ ‡æ¡†å‡º ROI
                    print("\n[INFO] Please select ROI...")
                    roi = cv2.selectROI(win_name, vis, fromCenter=False, showCrosshair=True)
                    x, y, w, h = roi
                    print(f"[INFO] ROI selected: x={x}, y={y}, w={w}, h={h}")
                    
                    if (w > 0 and h > 0):
                        init_bbox = [float(x), float(y), float(w), float(h)]
                        # åšä¸€æ¬¡é¢„å¤„ç†å¹¶åˆå§‹åŒ– tracker
                        print("[INFO] Preprocessing image...")
                        color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float = preprocess_rgb_depth(
                            color_bgr, depth_raw, depth_scale
                        )
                        print(f"[INFO] Image preprocessed. Shape: {color_rgb_uint8.shape}")
                        
                        # åˆå§‹åŒ–è·Ÿè¸ªå™¨
                        tracker.initialize(color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float, init_bbox)
                        
                        # æ£€æŸ¥æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
                        if tracker.initialized:
                            print(f"\n[SUCCESS] âœ“âœ“âœ“ Tracking started! Target bbox: {init_bbox}\n")
                        else:
                            print(f"\n[ERROR] âœ—âœ—âœ— Initialization failed! Please check errors above.\n")
                            init_bbox = None
                    else:
                        init_bbox = None
                        print("[WARNING] Invalid ROI selection (w or h is 0), please try again")
                continue

            # ä¹‹åï¼šæ­£å¸¸è·Ÿè¸ª

            # ä¹‹åï¼šæ­£å¸¸è·Ÿè¸ª
            t0 = time.time()
            color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float = preprocess_rgb_depth(
                color_bgr, depth_raw, depth_scale
            )
            bbox = tracker.track(color_rgb_uint8, depth_3ch_uint8, color_rgb_float, depth_3ch_float, frame_id)
            t1 = time.time()

            x, y, w, h = bbox
            
            # æ¯50å¸§æ‰“å°ä¸€æ¬¡bboxä¿¡æ¯ç”¨äºè°ƒè¯•
            if frame_id % 50 == 0:
                print(f"[DEBUG] Frame {frame_id}: bbox=[{x:.1f}, {y:.1f}, {w:.1f}, {h:.1f}], FPS={1.0/(t1-t0):.1f}")
            
            # ğŸ”’ æ£€æµ‹åˆ°æ¼‚ç§»æ—¶ï¼Œä¿®æ”¹bboxé¢œè‰²ä¸ºçº¢è‰²è­¦å‘Š
            box_color = (0, 255, 0)  # é»˜è®¤ç»¿è‰²
            if hasattr(tracker, '_confidence_history') and len(tracker._confidence_history) >= 5:
                recent_avg = sum(tracker._confidence_history[-5:]) / 5
                if recent_avg < 0.6:
                    box_color = (0, 0, 255)  # æ¼‚ç§»æ—¶æ˜¾ç¤ºçº¢è‰²æ¡†
            
            p1 = (int(x), int(y))
            p2 = (int(x + w), int(y + h))
            cv2.rectangle(vis, p1, p2, box_color, 2)

            fps = 1.0 / max(1e-6, (t1 - t0))
            cv2.putText(vis, f"FPS: {fps:.1f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºå¸§å·
            cv2.putText(vis, f"Frame: {frame_id}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºè·Ÿè¸ªç½®ä¿¡åº¦ï¼ˆå¸®åŠ©è¯Šæ–­è·Ÿè¸ªè´¨é‡ï¼‰
            if hasattr(tracker, 'last_confidence'):
                conf = tracker.last_confidence
                # ç½®ä¿¡åº¦é¢œè‰²ï¼šé«˜(ç»¿) -> ä¸­(é»„) -> ä½(çº¢)
                if conf > 0.85:
                    conf_color = (0, 255, 0)  # ç»¿è‰² - å¾ˆç¨³å®š
                elif conf > 0.7:
                    conf_color = (0, 255, 255)  # é»„è‰² - ä¸€èˆ¬
                elif conf > 0.5:
                    conf_color = (0, 165, 255)  # æ©™è‰² - ä¸ç¨³å®š
                else:
                    conf_color = (0, 0, 255)  # çº¢è‰² - å¯èƒ½æ¼‚ç§»
                cv2.putText(vis, f"Conf: {conf:.3f}", (10, 90),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, conf_color, 2)
            
            # æ˜¾ç¤ºæ¼‚ç§»è­¦å‘Š
            if hasattr(tracker, '_confidence_history') and len(tracker._confidence_history) >= 5:
                recent_avg = sum(tracker._confidence_history[-5:]) / 5
                if recent_avg < 0.6:
                    cv2.putText(vis, "WARNING: Possible Drift!", (10, 120),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    cv2.putText(vis, "Press 's' to re-select", (10, 145),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            # æ˜¾ç¤ºæ·±åº¦å›¾ï¼ˆç”¨äºéªŒè¯æ·±åº¦ä¿¡æ¯ï¼‰
            depth_colormap = cv2.applyColorMap(
                cv2.convertScaleAbs(depth_raw, alpha=0.03), 
                cv2.COLORMAP_JET
            )
            cv2.rectangle(depth_colormap, p1, p2, (0, 255, 0), 2)
            cv2.putText(depth_colormap, "Depth", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            cv2.imshow(win_name, vis)
            cv2.imshow("Depth View", depth_colormap)  # æ˜¾ç¤ºæ·±åº¦å›¾çª—å£

            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
            elif key == ord('s'):  # ğŸ”„ è·Ÿè¸ªè¿‡ç¨‹ä¸­æŒ‰'s'é‡æ–°åˆå§‹åŒ–
                print("\n" + "="*60)
                print("[INFO] ğŸ”„ Re-initialization requested...")
                print("[INFO] Please select new target ROI...")
                print("="*60)
                
                # æš‚åœå½“å‰ç”»é¢ï¼Œè®©ç”¨æˆ·é‡æ–°é€‰æ‹©
                roi = cv2.selectROI(win_name, vis, fromCenter=False, showCrosshair=True)
                x_new, y_new, w_new, h_new = roi
                
                if w_new > 0 and h_new > 0:
                    print(f"[INFO] New ROI selected: x={x_new}, y={y_new}, w={w_new}, h={h_new}")
                    init_bbox = [float(x_new), float(y_new), float(w_new), float(h_new)]
                    
                    # é‡æ–°åˆå§‹åŒ–è·Ÿè¸ªå™¨
                    print("[INFO] Re-initializing tracker...")
                    color_rgb_uint8_new, depth_3ch_uint8_new, color_rgb_float_new, depth_3ch_float_new = preprocess_rgb_depth(
                        color_bgr, depth_raw, depth_scale
                    )
                    tracker.initialize(color_rgb_uint8_new, depth_3ch_uint8_new, color_rgb_float_new, depth_3ch_float_new, init_bbox)
                    
                    if tracker.initialized:
                        print("\n" + "="*60)
                        print(f"[SUCCESS] âœ… Tracker re-initialized successfully!")
                        print(f"[SUCCESS] âœ… New target bbox: {init_bbox}")
                        print("="*60 + "\n")
                        frame_id = 0  # é‡ç½®å¸§è®¡æ•°
                    else:
                        print("[ERROR] Re-initialization failed!")
                else:
                    print("[WARNING] Invalid ROI, keeping current tracking...")
                
                continue  # ç»§ç»­è·Ÿè¸ªå¾ªç¯

            frame_id += 1

    except KeyboardInterrupt:
        print("\n[INFO] Interrupted by user")
    except Exception as e:
        print(f"[ERROR] Unexpected error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("[INFO] Cleaning up...")
        pipeline.stop()
        cv2.destroyAllWindows()
        print("[INFO] Done.")


if __name__ == "__main__":
    main()

