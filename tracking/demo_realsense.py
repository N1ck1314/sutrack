#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Âü∫‰∫é test.py ÁöÑ D435i ÂÆûÊó∂Ë∑üË∏™ Demo

Ê®°‰ªø test.py ÁöÑÊ†áÂáÜÁî®Ê≥ïÔºå‰ΩøÁî® Tracker Á±ªËøõË°åÂÆûÊó∂RGB-DË∑üË∏™

ËøêË°åÊñπÂºèÔºö
  1) conda activate sutrack
  2) Á°Æ‰øùÔºöexport PYTHONPATH=/ÁªùÂØπË∑ØÂæÑ/SUTrack:$PYTHONPATH
  3) python demo_realsense.py sutrack sutrack_b224 --debug 1

Êìç‰ΩúËØ¥ÊòéÔºö
  - Êåâ 's' ÈîÆÔºöÈÄâÂèñÂàùÂßãÁõÆÊ†áÔºàÁî®Èº†Ê†áÊ°ÜÈÄâÔºâ
  - Êåâ 'r' ÈîÆÔºöÈáçÊñ∞ÂàùÂßãÂåñ
  - Êåâ ESCÔºöÈÄÄÂá∫
"""

import os
import sys
import argparse
import time
import cv2
import numpy as np
import pyrealsense2 as rs

# Ê∑ªÂä†Ë∑ØÂæÑ‰ª•ÂØºÂÖ• SUTrack Ê®°Âùó
env_path = os.path.join(os.path.dirname(__file__), '..')
if env_path not in sys.path:
    sys.path.append(env_path)

from lib.test.evaluation.tracker import Tracker


class RealSenseSequence:
    """
    Ê®°ÊãüÊï∞ÊçÆÈõÜÊé•Âè£ÁöÑ RealSense Áõ∏Êú∫Â∫èÂàó
    ËÆ© Tracker ‰ª•‰∏∫Âú®Â§ÑÁêÜÊ†áÂáÜÊï∞ÊçÆÈõÜ
    """
    
    def __init__(self):
        self.pipeline = None
        self.align = None
        self.depth_scale = None
        self.frame_id = 0
        self.current_frame = None
        self.ground_truth = None  # ÂÆûÊó∂Ë∑üË∏™Ê≤°ÊúâGT
        
        print("[INFO] Initializing RealSense camera...")
        self._init_camera()
        
    def _init_camera(self):
        """ÂàùÂßãÂåñ D435i Áõ∏Êú∫"""
        self.pipeline = rs.pipeline()
        config = rs.config()
        
        # ÈÖçÁΩÆÊµÅ
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        
        profile = self.pipeline.start(config)
        
        # Ê∑±Â∫¶ÂØπÈΩêÂà∞ÂΩ©Ëâ≤
        align_to = rs.stream.color
        self.align = rs.align(align_to)
        
        # Ëé∑ÂèñÊ∑±Â∫¶ÊØî‰æã
        depth_sensor = profile.get_device().first_depth_sensor()
        self.depth_scale = depth_sensor.get_depth_scale()
        
        print(f"[INFO] RealSense started. depth_scale = {self.depth_scale:.6f} m/unit")
        
        # Á≠âÂæÖÁõ∏Êú∫Á®≥ÂÆö
        print("[INFO] Waiting for camera to stabilize...")
        for _ in range(30):
            try:
                self.pipeline.wait_for_frames(timeout_ms=1000)
            except:
                pass
        
    def get_frame(self, timeout_ms=5000):
        """Ëé∑Âèñ‰∏ÄÂ∏ßÊï∞ÊçÆÔºåËøîÂõû 6 ÈÄöÈÅì RGBD ÂõæÂÉè"""
        try:
            frames = self.pipeline.wait_for_frames(timeout_ms)
            aligned_frames = self.align.process(frames)
            
            color_frame = aligned_frames.get_color_frame()
            depth_frame = aligned_frames.get_depth_frame()
            
            if not color_frame or not depth_frame:
                return None
                
            # Ëé∑ÂèñÂéüÂßãÊï∞ÊçÆ
            color_bgr = np.asanyarray(color_frame.get_data())  # (H,W,3) BGR uint8
            depth_raw = np.asanyarray(depth_frame.get_data())  # (H,W) uint16
            
            # È¢ÑÂ§ÑÁêÜ‰∏∫6ÈÄöÈÅì RGBD
            rgbd_image = self._preprocess_rgbd(color_bgr, depth_raw)
            
            self.current_frame = rgbd_image
            self.frame_id += 1
            
            return rgbd_image, color_bgr  # ËøîÂõûÂ§ÑÁêÜÂêéÁöÑRGBDÂíåÂéüÂßãBGR(Áî®‰∫éÊòæÁ§∫)
            
        except Exception as e:
            print(f"[ERROR] Failed to get frame: {e}")
            return None
    
    def _preprocess_rgbd(self, color_bgr, depth_raw, max_dist_m=5.0):
        """
        È¢ÑÂ§ÑÁêÜ‰∏∫6ÈÄöÈÅìRGBDÂõæÂÉè
        
        Returns:
            rgbd_image: (H,W,6) uint8 [0-255]
            Ââç3ÈÄöÈÅì: RGB, Âêé3ÈÄöÈÅì: Depth(ÈáçÂ§ç3Ê¨°)
        """
        # BGR -> RGB
        color_rgb = cv2.cvtColor(color_bgr, cv2.COLOR_BGR2RGB)
        
        # Ê∑±Â∫¶Â§ÑÁêÜ: raw -> meters -> [0,1] -> [0,255]
        depth_m = depth_raw.astype(np.float32) * self.depth_scale
        depth_m = np.clip(depth_m, 0.0, max_dist_m)
        depth_norm = depth_m / max_dist_m  # [0,1]
        depth_uint8 = (depth_norm * 255.0).astype(np.uint8)
        
        # Ê∑±Â∫¶Êâ©Â±ï‰∏∫3ÈÄöÈÅì
        depth_3ch = np.stack([depth_uint8, depth_uint8, depth_uint8], axis=2)
        
        # ÂêàÂπ∂‰∏∫6ÈÄöÈÅì
        rgbd_image = np.concatenate([color_rgb, depth_3ch], axis=2)
        
        return rgbd_image
    
    def cleanup(self):
        """Ê∏ÖÁêÜËµÑÊ∫ê"""
        if self.pipeline:
            self.pipeline.stop()
        cv2.destroyAllWindows()


class RealtimeTracker:
    """
    ÂÆûÊó∂Ë∑üË∏™Âô®ÂåÖË£ÖÁ±ª
    Ê®°‰ªø test.py ‰∏≠ run_dataset ÁöÑÈÄªËæë
    """
    
    def __init__(self, tracker_name, tracker_param, debug=0):
        self.tracker_name = tracker_name
        self.tracker_param = tracker_param
        self.debug = debug
        
        # ÂàõÂª∫Â∫èÂàóÔºàÁõ∏Êú∫Êé•Âè£Ôºâ
        self.sequence = RealSenseSequence()
        
        # ÂàõÂª∫Ë∑üË∏™Âô®ÔºàÊ®°‰ªø test.pyÔºâ
        print(f"[INFO] Creating tracker: {tracker_name} with param: {tracker_param}")
        self.tracker = Tracker(tracker_name, tracker_param, 'demo', run_id=None)
        
        # Ëé∑ÂèñÂèÇÊï∞Âπ∂ÂàõÂª∫Ë∑üË∏™Âô®ÂÆû‰æã
        params = self.tracker.get_parameters()
        params.debug = debug
        
        # üîß Á¶ÅÁî®ÊñáÊú¨Ê®°ÊÄÅÂíåCLIP
        print(f"[INFO] Disabling text modality and CLIP...")
        self._disable_text_modality(params)
        
        # ‰øÆÂ§çÈ¢ÑËÆ≠ÁªÉÊùÉÈáçË∑ØÂæÑÈóÆÈ¢ò
        print(f"[INFO] Checking and fixing pretrained paths...")
        self._fix_pretrained_paths(params)
        
        # ÂàõÂª∫Ë∑üË∏™Âô®ÂÆû‰æãÔºàÊ®°‰ªø run_sequenceÔºâ
        self.tracker_impl = self.tracker.create_tracker(params)
        
        print("[INFO] Tracker created successfully.")
        
        # ÂàùÂßãÂåñÁä∂ÊÄÅ
        self.initialized = False
        self.init_bbox = None
    
    def _disable_text_modality(self, params):
        """Á¶ÅÁî®ÊñáÊú¨Ê®°ÊÄÅÂíåCLIPÁõ∏ÂÖ≥ÂäüËÉΩ"""
        cfg = params.cfg
        
        # Á¶ÅÁî®ÊñáÊú¨ÁºñÁ†ÅÂô®
        if hasattr(cfg.MODEL, 'TEXT_ENCODER'):
            print("[INFO] üîß Disabling text encoder...")
            cfg.MODEL.TEXT_ENCODER.TYPE = None  # Á¶ÅÁî®ÊñáÊú¨ÁºñÁ†ÅÂô®
        
        # Á¶ÅÁî®Â§öÊ®°ÊÄÅËØ≠Ë®ÄÂäüËÉΩ
        if hasattr(cfg.DATA, 'MULTI_MODAL_LANGUAGE'):
            print("[INFO] üîß Disabling multi-modal language...")
            cfg.DATA.MULTI_MODAL_LANGUAGE = False
        
        # Á¶ÅÁî®ÊâÄÊúâÊï∞ÊçÆÈõÜÁöÑNLPÂäüËÉΩ
        if hasattr(cfg.DATA, 'USE_NLP'):
            print("[INFO] üîß Disabling NLP for all datasets...")
            for dataset_key in cfg.DATA.USE_NLP:
                cfg.DATA.USE_NLP[dataset_key] = False
        
        # ÊµãËØïÊó∂Á¶ÅÁî®ËØ≠Ë®ÄÊ®°ÊÄÅ
        if hasattr(cfg.TEST, 'MULTI_MODAL_LANGUAGE'):
            print("[INFO] üîß Disabling language modality in TEST...")
            if hasattr(cfg.TEST.MULTI_MODAL_LANGUAGE, 'DEFAULT'):
                cfg.TEST.MULTI_MODAL_LANGUAGE.DEFAULT = False
            else:
                cfg.TEST.MULTI_MODAL_LANGUAGE = {'DEFAULT': False}
        
        # ÊµãËØïÊó∂Á¶ÅÁî®NLP
        if hasattr(cfg.TEST, 'USE_NLP'):
            print("[INFO] üîß Disabling NLP in TEST...")
            if hasattr(cfg.TEST.USE_NLP, 'DEFAULT'):
                cfg.TEST.USE_NLP.DEFAULT = False
            else:
                cfg.TEST.USE_NLP = {'DEFAULT': False}
        
        # Á°Æ‰øùÂè™‰ΩøÁî®ËßÜËßâÊ®°ÊÄÅ
        if hasattr(cfg.TEST, 'MULTI_MODAL_VISION'):
            print("[INFO] üîß Enabling vision-only mode...")
            if hasattr(cfg.TEST.MULTI_MODAL_VISION, 'DEFAULT'):
                cfg.TEST.MULTI_MODAL_VISION.DEFAULT = True
            else:
                cfg.TEST.MULTI_MODAL_VISION = {'DEFAULT': True}
        
        # üîß ‰øÆÂ§çRGBDÊîØÊåÅÔºöÂº∫Âà∂ËÆæÁΩÆ6ÈÄöÈÅìËæìÂÖ•
        print("[INFO] üîß Configuring RGBD support...")
        self._force_rgbd_support(cfg)
        
        # Â¶ÇÊûúÊúâ‰ªªÂä°Áõ∏ÂÖ≥ÁöÑËÆæÁΩÆÔºå‰πüÁ¶ÅÁî®ËØ≠Ë®Ä‰ªªÂä°
        if hasattr(cfg.MODEL, 'TASK_INDEX'):
            print("[INFO] üîß Adjusting task settings for vision-only...")
            # ‰øùÊåÅËßÜËßâ‰ªªÂä°ÔºåÁ¶ÅÁî®ÈúÄË¶ÅËØ≠Ë®ÄÁöÑ‰ªªÂä°
            # ËøôÈáå‰∏ç‰øÆÊîπTASK_INDEXÔºåÂõ†‰∏∫Ê®°ÂûãÊû∂ÊûÑÂèØËÉΩ‰æùËµñÂÆÉ
        
        print("[SUCCESS] ‚úÖ Text modality and CLIP disabled - Vision-only mode enabled")
        
        # üîç Ê£ÄÊü•Ê®°ÂûãÊòØÂê¶ÊîØÊåÅRGBD
        self._check_rgbd_support(params)
    
    def _force_rgbd_support(self, cfg):
        """Âº∫Âà∂ÈÖçÁΩÆRGBDÊîØÊåÅ"""
        print("[INFO]    - Forcing RGBD configuration...")
        
        # 1. ËÆæÁΩÆÁºñÁ†ÅÂô®ËæìÂÖ•ÈÄöÈÅì‰∏∫6
        if hasattr(cfg.MODEL, 'ENCODER'):
            print("[INFO]    - Setting encoder input channels to 6...")
            cfg.MODEL.ENCODER.IN_CHANS = 6  # Âº∫Âà∂ËÆæÁΩÆ‰∏∫6ÈÄöÈÅì
            if hasattr(cfg.MODEL.ENCODER, 'in_chans'):
                cfg.MODEL.ENCODER.in_chans = 6
        
        # 2. Êâ©Â±ïÊï∞ÊçÆÂΩí‰∏ÄÂåñÂèÇÊï∞Âà∞6ÈÄöÈÅì
        if hasattr(cfg.DATA, 'MEAN') and len(cfg.DATA.MEAN) == 3:
            print("[INFO]    - Extending normalization parameters to 6 channels...")
            # RGBÈÄöÈÅìÁöÑÂΩí‰∏ÄÂåñÂèÇÊï∞
            rgb_mean = cfg.DATA.MEAN
            rgb_std = cfg.DATA.STD
            
            # ‰∏∫Ê∑±Â∫¶ÈÄöÈÅìÊ∑ªÂä†ÂΩí‰∏ÄÂåñÂèÇÊï∞Ôºà‰ΩøÁî®ImageNetÁöÑÂùáÂÄºÂíåÊñπÂ∑ÆÔºâ
            depth_mean = [0.485, 0.456, 0.406]  # Â§çÁî®RGBÁöÑÂèÇÊï∞
            depth_std = [0.229, 0.224, 0.225]   # Â§çÁî®RGBÁöÑÂèÇÊï∞
            
            # Êâ©Â±ïÂà∞6ÈÄöÈÅìÔºöRGB + Depth
            cfg.DATA.MEAN = rgb_mean + depth_mean
            cfg.DATA.STD = rgb_std + depth_std
            
            print(f"[INFO]    - New MEAN: {cfg.DATA.MEAN}")
            print(f"[INFO]    - New STD: {cfg.DATA.STD}")
        
        # 3. Á°Æ‰øùÂ§öÊ®°ÊÄÅËßÜËßâÂºÄÂêØ
        if hasattr(cfg.DATA, 'MULTI_MODAL_VISION'):
            cfg.DATA.MULTI_MODAL_VISION = True
        
        print("[INFO]    - RGBD support configured successfully")
    
    def _check_rgbd_support(self, params):
        """Ê£ÄÊü•Ê®°ÂûãRGBDÊîØÊåÅÊÉÖÂÜµ"""
        cfg = params.cfg
        
        print("\n" + "="*50)
        print("[üîç RGBD SUPPORT CHECK]")
        print("="*50)
        
        # Ê£ÄÊü•ÁºñÁ†ÅÂô®ÈÖçÁΩÆ
        if hasattr(cfg.MODEL, 'ENCODER'):
            encoder_type = getattr(cfg.MODEL.ENCODER, 'TYPE', 'Unknown')
            print(f"Encoder type: {encoder_type}")
            
            # Ê£ÄÊü•ËæìÂÖ•ÈÄöÈÅìÊï∞
            input_channels = None
            for attr in ['in_chans', 'IN_CHANS', 'INPUT_CHANNELS']:
                if hasattr(cfg.MODEL.ENCODER, attr):
                    input_channels = getattr(cfg.MODEL.ENCODER, attr)
                    break
            
            if input_channels == 6:
                print("‚úÖ Model supports 6-channel RGBD input")
            elif input_channels == 3:
                print("‚ö†Ô∏è  Model configured for 3-channel RGB input")
                print("   Depth information may not be fully utilized")
            else:
                print(f"‚ùì Input channels: {input_channels}")
        
        # Ê£ÄÊü•È¢ÑÂ§ÑÁêÜÈÖçÁΩÆ
        if hasattr(cfg.DATA, 'MEAN') and hasattr(cfg.DATA, 'STD'):
            mean_channels = len(cfg.DATA.MEAN)
            std_channels = len(cfg.DATA.STD)
            print(f"Normalization channels: MEAN={mean_channels}, STD={std_channels}")
            
            if mean_channels == 6 and std_channels == 6:
                print("‚úÖ Preprocessing configured for RGBD")
            else:
                print("‚ö†Ô∏è  Preprocessing may be RGB-only")
        
        print("="*50 + "\n")
    
    def _fix_pretrained_paths(self, params):
        """‰øÆÂ§çÈ¢ÑËÆ≠ÁªÉÊùÉÈáçË∑ØÂæÑÈóÆÈ¢ò"""
        cfg = params.cfg
        
        # Ê£ÄÊü•ÁºñÁ†ÅÂô®È¢ÑËÆ≠ÁªÉË∑ØÂæÑ
        if hasattr(cfg.MODEL.ENCODER, 'PRETRAIN_TYPE'):
            pretrain_path = cfg.MODEL.ENCODER.PRETRAIN_TYPE
            print(f"[DEBUG] Original pretrain path: {pretrain_path}")
            
            # Â¶ÇÊûúÊòØÁõ∏ÂØπË∑ØÂæÑ‰∏îÊñá‰ª∂‰∏çÂ≠òÂú®
            if not os.path.isabs(pretrain_path) and not os.path.exists(pretrain_path):
                # Â∞ùËØïÂá†‰∏™ÂèØËÉΩÁöÑ‰ΩçÁΩÆ
                possible_paths = [
                    f"/home/nick/code/code.sutrack/SUTrack/{pretrain_path}",
                    f"/home/nick/code/code.sutrack/SUTrack/pretrained/{os.path.basename(pretrain_path)}",
                    f"/home/nick/code/code.sutrack/SUTrack/checkpoints/{os.path.basename(pretrain_path)}",
                    f"/home/nick/code/code.sutrack/SUTrack/checkpoints_backup/{os.path.basename(pretrain_path)}",
                ]
                
                found = False
                for path in possible_paths:
                    if os.path.exists(path):
                        print(f"[INFO] ‚úÖ Found pretrained file at: {path}")
                        cfg.MODEL.ENCODER.PRETRAIN_TYPE = path
                        found = True
                        break
                
                if not found:
                    print(f"[WARNING] ‚ö†Ô∏è  Pretrained file not found: {pretrain_path}")
                    print(f"[INFO] üîß Disabling encoder pretraining...")
                    # ÊñπÊ°à1: ËÆæÁΩÆ‰∏∫NoneÁ¶ÅÁî®È¢ÑËÆ≠ÁªÉ
                    cfg.MODEL.ENCODER.PRETRAIN_TYPE = None
                    # ÊñπÊ°à2: ÊàñËÄÖËÆæÁΩÆ‰∏Ä‰∏™Á©∫Â≠óÁ¨¶‰∏≤
                    # cfg.MODEL.ENCODER.PRETRAIN_TYPE = ""
                    print(f"[INFO] ‚úÖ Encoder will be initialized randomly")
            else:
                print(f"[INFO] ‚úÖ Pretrained path exists: {pretrain_path}")
        
    def run_interactive(self):
        """ËøêË°å‰∫§‰∫íÂºèË∑üË∏™"""
        print("\n" + "="*60)
        print("Interactive Tracking Started!")
        print("Controls:")
        print("  's' - Select target (mouse selection)")
        print("  'r' - Re-initialize tracking") 
        print("  ESC - Exit")
        print("="*60 + "\n")
        
        win_name = f"SUTrack Real-time Tracking ({self.tracker_name})"
        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
        
        frame_id = 0
        
        try:
            while True:
                # Ëé∑ÂèñÂ∏ß
                result = self.sequence.get_frame()
                if result is None:
                    print("[WARNING] Failed to get frame, skipping...")
                    continue
                    
                rgbd_image, color_bgr = result
                vis = color_bgr.copy()
                
                # Á¨¨‰∏ÄÊ¨°ÊàñÊú™ÂàùÂßãÂåñÔºöÁ≠âÂæÖÁî®Êà∑ÈÄâÊã©ÁõÆÊ†á
                if not self.initialized:
                    cv2.putText(vis, "Press 's' to select target, ESC to quit",
                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                                (0, 0, 255), 2)
                    cv2.imshow(win_name, vis)
                    
                    key = cv2.waitKey(1) & 0xFF
                    if key == 27:  # ESC
                        break
                    elif key == ord('s'):
                        self._select_target(vis, rgbd_image, win_name)
                    continue
                
                # Ê≠£Â∏∏Ë∑üË∏™
                t_start = time.time()
                
                # Ë∞ÉÁî®Ë∑üË∏™Âô®ÔºàÊ®°‰ªø run_sequence ÁöÑÈÄªËæëÔºâ
                output = self.tracker_impl.track(rgbd_image)
                
                t_end = time.time()
                
                # ÊèêÂèñÁªìÊûú
                bbox, confidence = self._extract_results(output)
                
                # ÂèØËßÜÂåñ
                self._visualize_results(vis, bbox, confidence, t_end - t_start, frame_id)
                
                cv2.imshow(win_name, vis)
                
                # Â§ÑÁêÜÊåâÈîÆ
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    break
                elif key == ord('r'):  # ÈáçÊñ∞ÂàùÂßãÂåñ
                    print("\n[INFO] Re-initialization requested...")
                    self._select_target(vis, rgbd_image, win_name)
                elif key == ord('s'):  # ÈÄâÊã©Êñ∞ÁõÆÊ†á
                    print("\n[INFO] New target selection requested...")
                    self._select_target(vis, rgbd_image, win_name)
                
                frame_id += 1
                
        except KeyboardInterrupt:
            print("\n[INFO] Interrupted by user")
        except Exception as e:
            print(f"[ERROR] Tracking error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.sequence.cleanup()
            print("[INFO] Tracking finished.")
    
    def _select_target(self, vis, rgbd_image, win_name):
        """ÈÄâÊã©Ë∑üË∏™ÁõÆÊ†á"""
        print("[INFO] Please select ROI...")
        roi = cv2.selectROI(win_name, vis, fromCenter=False, showCrosshair=True)
        x, y, w, h = roi
        
        if w > 0 and h > 0:
            self.init_bbox = [float(x), float(y), float(w), float(h)]
            
            # ÂàùÂßãÂåñË∑üË∏™Âô®ÔºàÊ®°‰ªø run_sequence ÁöÑÂàùÂßãÂåñÈÄªËæëÔºâ
            init_info = {'init_bbox': self.init_bbox}
            
            print(f"[INFO] Initializing tracker with bbox: {self.init_bbox}")
            
            try:
                out = self.tracker_impl.initialize(rgbd_image, init_info)
                self.initialized = True
                print(f"[SUCCESS] Tracker initialized successfully!")
                
                if self.debug:
                    print(f"[DEBUG] Init output: {type(out)}")
                    
            except Exception as e:
                print(f"[ERROR] Tracker initialization failed: {e}")
                import traceback
                traceback.print_exc()
                self.initialized = False
        else:
            print("[WARNING] Invalid ROI selection")
    
    def _extract_results(self, output):
        """ÊèêÂèñË∑üË∏™ÁªìÊûú"""
        bbox = None
        confidence = 0.0
        
        if isinstance(output, dict):
            # ÊèêÂèñbbox
            for key in ['target_bbox', 'bbox', 'pred_bbox']:
                if key in output:
                    bbox = output[key]
                    break
            
            # ÊèêÂèñconfidence  
            for key in ['best_score', 'confidence', 'score']:
                if key in output:
                    confidence = output[key]
                    if hasattr(confidence, 'item'):  # tensor
                        confidence = confidence.item()
                    break
                    
        elif hasattr(output, 'target_bbox'):
            bbox = output.target_bbox
            if hasattr(output, 'best_score'):
                confidence = output.best_score
                
        # ËΩ¨Êç¢bboxÊ†ºÂºè
        if bbox is not None:
            if hasattr(bbox, 'detach'):  # tensor
                bbox = bbox.detach().cpu().numpy()
            if isinstance(bbox, np.ndarray):
                bbox = bbox.tolist()
        else:
            bbox = self.init_bbox if self.init_bbox else [0, 0, 50, 50]
            
        return bbox, confidence
    
    def _visualize_results(self, vis, bbox, confidence, elapsed_time, frame_id):
        """ÂèØËßÜÂåñË∑üË∏™ÁªìÊûú"""
        x, y, w, h = bbox
        
        # Ê†πÊçÆÁΩÆ‰ø°Â∫¶ÈÄâÊã©È¢úËâ≤
        if confidence > 0.8:
            color = (0, 255, 0)  # ÁªøËâ≤ - È´òÁΩÆ‰ø°Â∫¶
        elif confidence > 0.6:
            color = (0, 255, 255)  # ÈªÑËâ≤ - ‰∏≠Á≠âÁΩÆ‰ø°Â∫¶
        else:
            color = (0, 0, 255)  # Á∫¢Ëâ≤ - ‰ΩéÁΩÆ‰ø°Â∫¶
            
        # ÁªòÂà∂bbox
        p1 = (int(x), int(y))
        p2 = (int(x + w), int(y + h))
        cv2.rectangle(vis, p1, p2, color, 2)
        
        # ÊòæÁ§∫‰ø°ÊÅØ
        fps = 1.0 / max(elapsed_time, 1e-6)
        cv2.putText(vis, f"FPS: {fps:.1f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(vis, f"Frame: {frame_id}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(vis, f"Conf: {confidence:.3f}", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.putText(vis, f"Box: [{x:.1f},{y:.1f},{w:.1f},{h:.1f}]", (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ‰ΩéÁΩÆ‰ø°Â∫¶Ë≠¶Âëä
        if confidence < 0.5:
            cv2.putText(vis, "WARNING: Low Confidence", (10, 150),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            cv2.putText(vis, "Press 'r' to re-init", (10, 175),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)


def main():
    """‰∏ªÂáΩÊï∞ - Ê®°‰ªø test.py ÁöÑÂèÇÊï∞Ëß£Êûê"""
    parser = argparse.ArgumentParser(description='Run SUTrack on RealSense D435i camera.')
    parser.add_argument('tracker_name', type=str, help='Name of tracking method (e.g., sutrack)')
    parser.add_argument('tracker_param', type=str, help='Name of config file (e.g., sutrack_b224)')
    parser.add_argument('--debug', type=int, default=0, help='Debug level (0=none, 1=basic, 2=verbose)')
    
    args = parser.parse_args()
    
    print("\n" + "="*80)
    print(f"SUTrack Real-time Demo")
    print(f"Tracker: {args.tracker_name}")
    print(f"Config: {args.tracker_param}")
    print(f"Debug: {args.debug}")
    print("="*80 + "\n")
    
    # È¢ÑÊ£ÄÊü•ÔºöÈ™åËØÅÂü∫Êú¨Ë∑ØÂæÑ
    print("[INFO] Pre-checking SUTrack installation...")
    
    # Ê£ÄÊü•‰∏ªË¶ÅÊùÉÈáçÊñá‰ª∂
    checkpoint_paths = [
        "/home/nick/code/code.sutrack/SUTrack/checkpoints/sutrack_t224.pth",
    ]
    
    found_checkpoints = []
    for path in checkpoint_paths:
        if os.path.exists(path):
            found_checkpoints.append(path)
            print(f"[INFO] ‚úÖ Found checkpoint: {os.path.basename(path)}")
    
    if not found_checkpoints:
        print("[WARNING] ‚ö†Ô∏è  No main checkpoints found! Tracker may not work properly.")
    
    # Ê£ÄÊü•È¢ÑËÆ≠ÁªÉÁºñÁ†ÅÂô®
    pretrain_paths = [
        "/home/nick/code/code.sutrack/SUTrack/pretrained/itpn/fast_itpn_tiny_1600e_1k.pt",
        "/home/nick/code/code.sutrack/SUTrack/pretrained/fast_itpn_tiny_1600e_1k.pt",
        "/home/nick/code/code.sutrack/SUTrack/checkpoints/fast_itpn_tiny_1600e_1k.pt",
    ]
    
    found_pretrains = []
    for path in pretrain_paths:
        if os.path.exists(path):
            found_pretrains.append(path)
            print(f"[INFO] ‚úÖ Found pretrained encoder: {os.path.basename(path)}")
    
    if not found_pretrains:
        print("[WARNING] ‚ö†Ô∏è  No pretrained encoder found. Will use random initialization.")
        print("[INFO] üí° This is OK - the main checkpoint contains trained encoder weights.")
    
    print("="*80 + "\n")
    
    try:
        # ÂàõÂª∫ÂÆûÊó∂Ë∑üË∏™Âô®
        tracker = RealtimeTracker(
            tracker_name=args.tracker_name,
            tracker_param=args.tracker_param,
            debug=args.debug
        )
        
        # ËøêË°å‰∫§‰∫íÂºèË∑üË∏™
        tracker.run_interactive()
        
    except Exception as e:
        print(f"[ERROR] Failed to start tracking: {e}")
        import traceback
        traceback.print_exc()
        
        # Êèê‰æõËß£ÂÜ≥ÊñπÊ°àÊèêÁ§∫
        print("\n" + "="*80)
        print("üí° TROUBLESHOOTING TIPS:")
        print("="*80)
        
        if "No such file or directory" in str(e) and "pretrained" in str(e):
            print("‚ùå Missing pretrained files detected!")
            print("üîß SOLUTIONS:")
            print("   1. Download missing pretrained files from the official repo")
            print("   2. Or try using sutrack_b224 instead of sutrack_t224:")
            print("      python demo_realsense.py sutrack sutrack_b224 --debug 1")
            print("   3. Or modify config to skip encoder pretraining")
        elif "checkpoint" in str(e).lower():
            print("‚ùå Checkpoint loading error!")
            print("üîß SOLUTIONS:")
            print("   1. Check if checkpoint files exist in checkpoints_backup/")
            print("   2. Verify checkpoint format and pytorch version compatibility")
            print("   3. Try re-downloading checkpoints")
        elif "CUDA" in str(e) or "GPU" in str(e):
            print("‚ùå GPU/CUDA error!")
            print("üîß SOLUTIONS:")
            print("   1. Check if CUDA is properly installed: nvidia-smi")
            print("   2. Check pytorch CUDA version: python -c 'import torch; print(torch.cuda.is_available())'")
            print("   3. Try CPU mode by modifying code")
        else:
            print("‚ùå General error occurred!")
            print("üîß GENERAL SOLUTIONS:")
            print("   1. Check SUTrack installation and dependencies")
            print("   2. Verify PYTHONPATH includes SUTrack directory")
            print("   3. Check if all required packages are installed")
        
        print("="*80 + "\n")
        
        return 1
    
    print("\n[INFO] Demo completed successfully.")
    return 0


if __name__ == '__main__':
    sys.exit(main())
