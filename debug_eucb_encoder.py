"""
è°ƒè¯• EUCB Encoder NaN é—®é¢˜
"""
import torch
import sys
sys.path.append('.')

from lib.config.sutrack_EUCB.config import cfg, update_config_from_file
from lib.models.sutrack_EUCB import build_sutrack

print("="*60)
print("ğŸ” è°ƒè¯• EUCB Encoder NaN é—®é¢˜")
print("="*60)

# åŠ è½½é…ç½®
config_path = "experiments/sutrack_EUCB/sutrack_eucb_t224.yaml"
update_config_from_file(config_path)

print("\nğŸ“‹ å…³é”®é…ç½®:")
print(f"  - ENCODER.TYPE: {cfg.MODEL.ENCODER.TYPE}")
print(f"  - ENCODER.DROP_PATH: {cfg.MODEL.ENCODER.DROP_PATH}")
print(f"  - ENCODER.PRETRAIN_TYPE: {cfg.MODEL.ENCODER.PRETRAIN_TYPE}")
print(f"  - DECODER.USE_EUCB: {cfg.MODEL.DECODER.USE_EUCB}")

# æ„å»ºæ¨¡å‹
print("\nğŸ—ï¸  æ„å»ºæ¨¡å‹...")
model = build_sutrack(cfg)
model.cuda()
model.eval()

print("âœ… æ¨¡å‹æ„å»ºæˆåŠŸ")

# åˆ›å»ºæµ‹è¯•è¾“å…¥
batch_size = 2
template_size = cfg.DATA.TEMPLATE.SIZE
search_size = cfg.DATA.SEARCH.SIZE

print(f"\nğŸ§ª åˆ›å»ºæµ‹è¯•è¾“å…¥ (batch_size={batch_size})...")
print(f"  - template: {batch_size} x 3 x {template_size} x {template_size}")
print(f"  - search: {batch_size} x 3 x {search_size} x {search_size}")

template = torch.randn(batch_size, 3, template_size, template_size).cuda()
search = torch.randn(batch_size, 3, search_size, search_size).cuda()
template_anno = torch.tensor([[0.4, 0.4, 0.2, 0.2]] * batch_size).cuda()
task_index = torch.tensor([0, 1]).cuda()

# æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰ NaN
assert not torch.isnan(template).any(), "Template è¾“å…¥æœ‰ NaNï¼"
assert not torch.isnan(search).any(), "Search è¾“å…¥æœ‰ NaNï¼"
print("âœ… è¾“å…¥æ•°æ®æ­£å¸¸ï¼ˆæ—  NaNï¼‰")

# å‰å‘ä¼ æ’­ - Encoder
print("\nğŸš€ æµ‹è¯• Encoder å‰å‘ä¼ æ’­...")
with torch.no_grad():
    try:
        encoder_output = model.forward_encoder(
            template_list=[template],
            search_list=[search],
            template_anno_list=[template_anno],
            text_src=None,
            task_index=task_index
        )
        
        # æ£€æŸ¥è¾“å‡º
        if isinstance(encoder_output, (list, tuple)):
            enc_tensor = encoder_output[0]
        else:
            enc_tensor = encoder_output
        
        print(f"âœ… Encoder è¾“å‡ºå½¢çŠ¶: {enc_tensor.shape}")
        print(f"   - dtype: {enc_tensor.dtype}")
        print(f"   - device: {enc_tensor.device}")
        
        # æ£€æŸ¥ NaN
        nan_count = torch.isnan(enc_tensor).sum().item()
        total_elements = enc_tensor.numel()
        
        if nan_count > 0:
            print(f"\nâŒ æ£€æµ‹åˆ° NaNï¼")
            print(f"   - NaN æ•°é‡: {nan_count} / {total_elements}")
            print(f"   - NaN æ¯”ä¾‹: {nan_count / total_elements * 100:.2f}%")
            
            # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯ NaN
            if nan_count == total_elements:
                print("   - âš ï¸  æ‰€æœ‰è¾“å‡ºéƒ½æ˜¯ NaNï¼")
            
            # å°è¯•æ‰¾å‡ºå“ªä¸€å±‚äº§ç”Ÿäº† NaN
            print("\nğŸ” å°è¯•å®šä½ NaN æ¥æº...")
            
            # æ£€æŸ¥ patch embedding
            print("   æ£€æŸ¥ patch_embed...")
            encoder_body = model.encoder.body
            with torch.no_grad():
                # Template patch embedding
                template_embed = encoder_body.patch_embed(template)
                if torch.isnan(template_embed).any():
                    print("   âŒ Template patch_embed è¾“å‡ºæœ‰ NaNï¼")
                else:
                    print("   âœ… Template patch_embed æ­£å¸¸")
                
                # Search patch embedding
                search_embed = encoder_body.patch_embed(search)
                if torch.isnan(search_embed).any():
                    print("   âŒ Search patch_embed è¾“å‡ºæœ‰ NaNï¼")
                else:
                    print("   âœ… Search patch_embed æ­£å¸¸")
        else:
            print("âœ… Encoder è¾“å‡ºæ­£å¸¸ï¼ˆæ—  NaNï¼‰")
            print(f"   - min: {enc_tensor.min().item():.6f}")
            print(f"   - max: {enc_tensor.max().item():.6f}")
            print(f"   - mean: {enc_tensor.mean().item():.6f}")
            print(f"   - std: {enc_tensor.std().item():.6f}")
            
            # æµ‹è¯• Decoder
            print("\nğŸš€ æµ‹è¯• Decoder å‰å‘ä¼ æ’­...")
            decoder_output, task_output = model.forward_decoder(encoder_output)
            print(f"âœ… Decoder è¾“å‡ºæ­£å¸¸")
            print(f"   - pred_boxes: {decoder_output['pred_boxes'].shape}")
            
    except Exception as e:
        print(f"\nâŒ å‰å‘ä¼ æ’­å¤±è´¥ï¼")
        print(f"   é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

print("\n" + "="*60)
print("è°ƒè¯•å®Œæˆ")
print("="*60)
